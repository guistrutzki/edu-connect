# ğŸ¯ Fluxo Simplificado: Ãudio â†’ Backend â†’ Emojis

## ğŸ¯ **OBJETIVO ÃšNICO**
Capturar Ã¡udio em tempo real, enviar para backend que converte em texto via ChatGPT e retorna emojis correspondentes.

## ğŸ”„ **FLUXO SIMPLES**

```
ğŸ¤ Ãudio â†’ ğŸŒ Backend â†’ ğŸ¤– ChatGPT â†’ ğŸ¨ Emojis â†’ ğŸ“± Tela
```

### **1. Captura de Ãudio (Frontend)**
- Usa Expo Audio Recording
- Envia buffer/streaming para backend
- Interface de gravaÃ§Ã£o

### **2. Processamento (Backend)**
- Recebe Ã¡udio via endpoint
- Converte Ã¡udio em texto via **OpenAI Whisper API**
- Analisa texto via **ChatGPT API** para extrair emojis
- Retorna emojis correspondentes

### **3. ExibiÃ§Ã£o (Frontend)**
- Recebe emojis do backend
- Exibe em tempo real
- Interface simples e acessÃ­vel

## ğŸ“ **ESTRUTURA SIMPLIFICADA**

### **Frontend (React Native + Expo)**
```
src/
â”œâ”€â”€ services/
â”‚   â”œâ”€â”€ AudioService.ts         # Captura e envio de Ã¡udio
â”‚   â””â”€â”€ ApiService.ts           # ComunicaÃ§Ã£o com backend
â”œâ”€â”€ components/
â”‚   â”œâ”€â”€ AudioCapture.tsx        # BotÃ£o de gravaÃ§Ã£o
â”‚   â””â”€â”€ EmojiDisplay.tsx        # Lista de emojis
â””â”€â”€ App.tsx                     # Componente principal
```

### **Backend (Node.js + Express)**
```
backend/
â”œâ”€â”€ routes/
â”‚   â””â”€â”€ audio.ts                # Endpoint POST /api/audio
â”œâ”€â”€ services/
â”‚   â”œâ”€â”€ WhisperService.ts       # OpenAI Whisper API
â”‚   â””â”€â”€ ChatGPTService.ts       # OpenAI ChatGPT API
â””â”€â”€ server.js                   # Servidor principal
```

## ğŸš€ **IMPLEMENTAÃ‡ÃƒO MÃNIMA**

### **DependÃªncias Frontend:**
- `expo-av` (gravaÃ§Ã£o de Ã¡udio)
- `zustand` (estado)
- `fetch` (comunicaÃ§Ã£o com backend)

### **DependÃªncias Backend:**
- `express` (servidor)
- `multer` (upload de arquivos)
- `openai` (Whisper + ChatGPT APIs)
- `cors` (CORS)

### **APIs Externas:**
- **OpenAI Whisper API** - ConversÃ£o Ã¡udio â†’ texto
- **OpenAI ChatGPT API** - AnÃ¡lise de texto â†’ emojis

### **Funcionalidades:**
- âœ… Gravar Ã¡udio no frontend
- âœ… Enviar Ã¡udio para backend
- âœ… Converter Ã¡udio em texto (Whisper)
- âœ… Analisar texto e extrair emojis (ChatGPT)
- âœ… Retornar emojis para frontend
- âœ… Exibir emojis na tela

## ğŸ¯ **RESULTADO ESPERADO**

1. UsuÃ¡rio clica "Gravar"
2. App captura Ã¡udio
3. App envia Ã¡udio para backend
4. Backend converte Ã¡udio em texto (Whisper)
5. Backend analisa texto e extrai emojis (ChatGPT)
6. Backend retorna emojis para app
7. App exibe emojis na tela
8. UsuÃ¡rio clica "Parar"
9. HistÃ³rico fica salvo na tela

## ğŸ”§ **ENDPOINT DO BACKEND**

```typescript
POST /api/audio
Content-Type: multipart/form-data

Body: {
  audio: File (buffer/streaming)
}

Response: {
  text: string,           // Texto transcrito completo
  content_emojis: [{      // Array de objetos com emoji e conteÃºdo
    emoji: string,        // CÃ³digo hex do emoji
    content: string       // Resumo descritivo do conteÃºdo
  }],
  confidence: number      // ConfianÃ§a da transcriÃ§Ã£o
}
```

## ğŸ¤– **PROMPT DO CHATGPT**

```
Analise o seguinte texto e extraia:

1. EMOJIS mais relevantes que representam:
   - EmoÃ§Ãµes expressas
   - Objetos mencionados  
   - AÃ§Ãµes descritas
   - Conceitos principais

2. CONTEÃšDOS DESCRITIVOS que representam resumos em portuguÃªs:
   - Conceitos educacionais (ex: "Aprendizado de matemÃ¡tica", "Estudo de ciÃªncias")
   - AÃ§Ãµes de aprendizado (ex: "ExplicaÃ§Ã£o de conceitos", "ResoluÃ§Ã£o de exercÃ­cios")
   - Objetos do ambiente escolar (ex: "Material didÃ¡tico", "Quadro de aula")
   - SÃ­mbolos matemÃ¡ticos (ex: "OperaÃ§Ã£o de adiÃ§Ã£o", "CÃ¡lculo numÃ©rico")
   - Elementos visuais (ex: "IlustraÃ§Ã£o conceitual", "RepresentaÃ§Ã£o grÃ¡fica")

Texto: "{texto_transcrito}"

Retorne um JSON com:
{
  "content_emojis": [
    {"emoji": "1F600", "content": "Bom dia e cumprimento"},
    {"emoji": "1F34E", "content": "Aprendizado de matemÃ¡tica"},
    {"emoji": "2764", "content": "OperaÃ§Ãµes bÃ¡sicas"}
  ]
}
```

## ğŸ“‹ **REQUISITOS DO BACKEND**

### **DependÃªncias NecessÃ¡rias:**
```json
{
  "express": "^4.18.0",
  "multer": "^1.4.5",
  "openai": "^4.0.0",
  "cors": "^2.8.5",
  "dotenv": "^16.0.0"
}
```

### **VariÃ¡veis de Ambiente:**
```env
OPENAI_API_KEY=sk-...
PORT=3000
```

### **Estrutura do Endpoint:**
```javascript
// POST /api/audio
// Content-Type: multipart/form-data
// Body: { audio: File }

// 1. Recebe arquivo de Ã¡udio via multer
// 2. Converte Ã¡udio em texto via OpenAI Whisper API
// 3. Analisa texto via OpenAI ChatGPT API
// 4. Retorna emojis correspondentes

// Response:
{
  "text": "Bom dia turma! Hoje vamos aprender matemÃ¡tica. Vamos estudar sobre nÃºmeros e operaÃ§Ãµes. Quem pode me dizer quanto Ã© dois mais trÃªs?",
  "content_emojis": [
    {"emoji": "1F44B", "content": "Cumprimento e saudaÃ§Ã£o"},
    {"emoji": "1F4DA", "content": "Estudo e aprendizado"},
    {"emoji": "1F522", "content": "NÃºmeros e matemÃ¡tica"},
    {"emoji": "2795", "content": "OperaÃ§Ã£o de adiÃ§Ã£o"}
  ],
  "confidence": 0.95
}
```

### **Fluxo de Processamento:**
1. **Upload**: Recebe arquivo de Ã¡udio via `multer`
2. **TranscriÃ§Ã£o**: Envia para `OpenAI Whisper API`
3. **AnÃ¡lise**: Envia texto para `OpenAI ChatGPT API` com prompt especÃ­fico
4. **Resposta**: Retorna texto + emojis + sÃ­mbolos de conteÃºdo para o frontend

### **ConfiguraÃ§Ãµes do Whisper:**
```javascript
const transcription = await openai.audio.transcriptions.create({
  file: audioFile,
  model: "whisper-1",
  language: "pt", // PortuguÃªs
  response_format: "json"
});
```

### **ConfiguraÃ§Ãµes do ChatGPT:**
```javascript
const completion = await openai.chat.completions.create({
  model: "gpt-3.5-turbo",
  messages: [
    {
      role: "system",
      content: "VocÃª Ã© um especialista em extrair emojis e sÃ­mbolos de conteÃºdo relevantes de textos educacionais. Retorne sempre um JSON vÃ¡lido."
    },
    {
      role: "user", 
      content: `Analise: "${transcribedText}"`
    }
  ],
  max_tokens: 200,
  response_format: { type: "json_object" }
});

// Parse da resposta
const analysis = JSON.parse(completion.choices[0].message.content);
const { content_emojis } = analysis;

// Retorna resposta formatada
return {
  text: transcribedText,
  content_emojis: content_emojis, // Array de objetos com emoji e conteÃºdo
  confidence: transcription.confidence || 0.95
};
```

**Simples, direto e funcional com IA!**
